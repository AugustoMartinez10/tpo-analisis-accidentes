# -*- coding: utf-8 -*-
"""TPO MIERCOLES NUEVO

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ux-tL65CVQUHia6x2HjlWOLPebk7BtJL

### Objetivo del Proyecto  
Este trabajo tiene como prop√≥sito analizar los accidentes de tr√°nsito ocurridos en Argentina entre 2017 y 2023.  
A partir de un enfoque exploratorio y de miner√≠a de datos, se busca identificar patrones temporales, geogr√°ficos y sociodemogr√°ficos asociados a la siniestralidad vial.  
La finalidad es aportar informaci√≥n √∫til para la toma de decisiones en materia de prevenci√≥n y seguridad vial.

## Hip√≥tesis Principal  
Existen zonas geogr√°ficas y franjas horarias donde los accidentes de tr√°nsito se concentran significativamente, lo que permite identificar puntos cr√≠ticos de siniestralidad.

## Hip√≥tesis Secundaria  
Las personas j√≥venes (menores de 25 a√±os) y los motociclistas presentan una mayor participaci√≥n en los accidentes de tr√°nsito en comparaci√≥n con otros grupos etarios y tipos de veh√≠culo.

## Dominio del Negocio y Relevancia  
La siniestralidad vial representa un problema social y econ√≥mico de alta relevancia en Argentina.  
El an√°lisis de datos de accidentes permite generar conocimiento para las autoridades de seguridad vial, municipios y organismos p√∫blicos, contribuyendo al dise√±o de pol√≠ticas de prevenci√≥n m√°s eficaces y focalizadas.

## T√©cnica de Miner√≠a de Datos Aplicada: Clustering Geogr√°fico  
Para detectar zonas de alta concentraci√≥n de accidentes se aplic√≥ la t√©cnica de agrupamiento (clustering) mediante el algoritmo KMeans.  
Este m√©todo permiti√≥ identificar grupos de siniestros en funci√≥n de su ubicaci√≥n geogr√°fica, generando conocimiento valioso sobre los llamados "puntos calientes" de siniestralidad.

## Conclusiones Finales  
El an√°lisis exploratorio y la aplicaci√≥n de t√©cnicas de miner√≠a de datos permitieron identificar los siguientes hallazgos relevantes:  

‚úî Los fines de semana y los horarios nocturnos concentran una mayor cantidad de accidentes.  
‚úî Los motociclistas y las personas j√≥venes se destacan como grupos de mayor participaci√≥n en los siniestros.  
‚úî Se identificaron zonas geogr√°ficas cr√≠ticas de alta concentraci√≥n de accidentes mediante clustering geogr√°fico.  

Estos resultados constituyen una base s√≥lida para dise√±ar pol√≠ticas de prevenci√≥n focalizadas y orientar los recursos en materia de seguridad vial.

# An√°lisis de Accidentes de Tr√°nsito en Argentina (2017-2023)
Trabajo Pr√°ctico - Ciencia de Datos - UADE  
Integrantes:

## Introducci√≥n  
En el presente trabajo se analizar√°n los accidentes de tr√°nsito registrados en Argentina entre los a√±os 2017 y 2023, utilizando un dataset p√∫blico provisto por la Subsecretar√≠a de Transporte.  
El objetivo es identificar patrones espaciales, temporales y sociodemogr√°ficos asociados a la siniestralidad vial, con el fin de aportar informaci√≥n √∫til para la toma de decisiones en materia de seguridad vial.  
Se busca determinar si existen zonas cr√≠ticas, franjas horarias o grupos poblacionales con mayor incidencia de accidentes.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import folium
from IPython.display import display
import re

"""## Carga de Datos  
A continuaci√≥n, se carga el dataset con los registros de accidentes de tr√°nsito y se visualizan las primeras filas para conocer su estructura.  

"""

import pandas as pd
# Reemplaz√° el siguiente link por el link de descarga directa
url = 'https://raw.githubusercontent.com/AugustoMartinez10/tpo-analisis-sube/refs/heads/main/SAT-MV-BU_2017-2023.csv'

df = pd.read_csv(url, sep=None, engine='python')

display(df.head())

"""## Sanitizaci√≥n y Preparaci√≥n de los Datos  
Se realiza un proceso de limpieza para garantizar la correcta manipulaci√≥n de los datos.  
Se eliminan columnas irrelevantes para el an√°lisis, se renombran algunas variables y se verifica la existencia de valores nulos.  
Tambi√©n se estandarizan las fechas y se crean variables nuevas que facilitar√°n los an√°lisis posteriores.  

"""

# Visualizamos las columnas para identificar las relevantes
df.columns.tolist()

# Selecci√≥n de columnas clave para el an√°lisis
columnas_relevantes = [
    'provincia_nombre', 'departamento_nombre', 'localidad_nombre',
    'latitud', 'longitud',
    'fecha_hecho', 'hora_hecho',
    'victima_sexo', 'victima_tr_edad', 'victima_vehiculo_ampliado',
    'inculpado_sexo', 'inculpado_tr_edad', 'inculpado_vehiculo_ampliado'
]

df = df[columnas_relevantes]
display(df.head())

# Sanitizaci√≥n general de columnas de texto
# Reemplazo de guiones, "Sin determinar" y "No corresponde" por NaN
for col in df.select_dtypes(include='object').columns:
    df[col] = df[col].replace(to_replace=r'^-+$', value=np.nan, regex=True)
    df[col] = df[col].replace(['Sin determinar', 'No corresponde'], np.nan)

# Conversi√≥n de fecha y extracci√≥n de variables adicionales
df['fecha_hecho'] = pd.to_datetime(df['fecha_hecho'], errors='coerce')
df['a√±o'] = df['fecha_hecho'].dt.year
df['mes'] = df['fecha_hecho'].dt.month
df['dia_semana'] = df['fecha_hecho'].dt.day_name()

# Conversi√≥n de hora a formato de 24 hs
# Filtrar valores v√°lidos antes de convertir
df_hora = df[
    (df['hora_hecho'].notna()) &
    (df['hora_hecho'] != 'Sin determinar') &
    (df['hora_hecho'] != 'No corresponde') &
    (df['hora_hecho'] != 'Perdido')
].copy()

# Convertir solo los v√°lidos
df_hora['hora'] = pd.to_datetime(df_hora['hora_hecho'], format='%H:%M:%S', errors='coerce').dt.hour
display(df_hora.head())

# Revisi√≥n de valores faltantes
df.isnull().sum()

"""## An√°lisis Exploratorio de los Datos  
A continuaci√≥n, se realiza un an√°lisis preliminar de la informaci√≥n para detectar patrones temporales y geogr√°ficos en la siniestralidad vial.  
Este paso permite comprender mejor la distribuci√≥n de los accidentes en funci√≥n de variables como el d√≠a de la semana, la hora y la ubicaci√≥n.

### Distribuci√≥n de Accidentes por D√≠a de la Semana  
Se analiza la cantidad de accidentes ocurridos en cada d√≠a de la semana para identificar posibles picos de siniestralidad.
"""

# Se eliminan registros sin fecha v√°lida
df_filtrado = df.dropna(subset=['dia_semana'])

# Conteo y gr√°fico
plt.figure(figsize=(8, 5))
orden_dias = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
sns.countplot(data=df_filtrado, x='dia_semana', order=orden_dias)
plt.title('Cantidad de Accidentes por D√≠a de la Semana')
plt.xlabel('D√≠a')
plt.ylabel('Cantidad de Accidentes')
plt.xticks(rotation=45)
plt.show()

# Agrupamiento de accidentes por d√≠a de la semana
accidentes_dia = df_filtrado['dia_semana'].value_counts().reset_index()
accidentes_dia.columns = ['dia_semana', 'cantidad']

# Exportar CSV
accidentes_dia.to_csv('accidentes_por_dia.csv', index=False)

# Descargar CSV
from google.colab import files
files.download('accidentes_por_dia.csv')

"""### Distribuci√≥n de Accidentes por Hora del D√≠a  
Se analiza la cantidad de accidentes en funci√≥n del horario para detectar franjas horarias de mayor siniestralidad.  

"""

# Se eliminan registros sin hora v√°lida
df_filtrado_hora = df_hora.dropna(subset=['hora'])

plt.figure(figsize=(8, 5))
sns.histplot(df_filtrado_hora['hora'], bins=24, kde=False)
plt.title('Distribuci√≥n Horaria de los Accidentes')
plt.xlabel('Hora del D√≠a')
plt.ylabel('Cantidad de Accidentes')
plt.show()

# Agrupamiento de accidentes por hora
accidentes_hora = df_filtrado_hora['hora'].value_counts().sort_index().reset_index()
accidentes_hora.columns = ['hora', 'cantidad']

# Exportar CSV
accidentes_hora.to_csv('accidentes_por_hora.csv', index=False)

# Descargar CSV
files.download('accidentes_por_hora.csv')

"""### Visualizaci√≥n Geogr√°fica de Accidentes  
Se genera un mapa interactivo que permite observar la ubicaci√≥n de los accidentes registrados.  
Debido al tama√±o del dataset, se filtran solo los registros que tienen coordenadas v√°lidas.  


"""

# Copia del dataframe para evitar modificar el original
df_mapa = df.copy()

# Convertir latitud y longitud a num√©rico, ignorando errores
df_mapa['latitud'] = pd.to_numeric(df_mapa['latitud'], errors='coerce')
df_mapa['longitud'] = pd.to_numeric(df_mapa['longitud'], errors='coerce')

# Filtrar solo los registros v√°lidos
df_mapa = df_mapa.dropna(subset=['latitud', 'longitud'])

# Crear mapa centrado en Argentina
m = folium.Map(location=[-38.41, -63.61], zoom_start=4)

# Agregar puntos al mapa
for _, row in df_mapa.iterrows():
    folium.CircleMarker(
        location=[row['latitud'], row['longitud']],
        radius=2,
        color='red',
        fill=True,
        fill_opacity=0.5
    ).add_to(m)

m

"""### An√°lisis de Grupos Etarios de V√≠ctimas  
Se analiza la distribuci√≥n de edad de las v√≠ctimas de accidentes de tr√°nsito.  
Para este an√°lisis, se filtran los registros que contienen un dato v√°lido en la variable de edad.  

"""

# Filtrar datos v√°lidos de edad de v√≠ctimas
df_victimas = df[
    (df['victima_tr_edad'].notna()) &
    (df['victima_tr_edad'] != 'No corresponde') &
    (df['victima_tr_edad'] != 'Sin determinar')
]

# Conteo por grupo etario
plt.figure(figsize=(10, 5))
sns.countplot(data=df_victimas, x='victima_tr_edad', order=sorted(df_victimas['victima_tr_edad'].unique()))
plt.title('Distribuci√≥n de Edad de las V√≠ctimas')
plt.xlabel('Grupo Etario')
plt.ylabel('Cantidad de Accidentes')
plt.xticks(rotation=45)
plt.show()

# Agrupamiento por edad de las v√≠ctimas
edad_victimas = df_victimas['victima_tr_edad'].value_counts().reset_index()
edad_victimas.columns = ['edad', 'cantidad']

# Exportar CSV
edad_victimas.to_csv('edad_victimas.csv', index=False)
from google.colab import files
files.download('edad_victimas.csv')

"""### An√°lisis por Tipo de Veh√≠culo de las V√≠ctimas  
Se analiza qu√© tipo de veh√≠culo conduc√≠an o en qu√© se transportaban las v√≠ctimas involucradas en los accidentes.  
Se filtran los registros que tienen un dato v√°lido en esta variable.  

"""

# Filtrar datos v√°lidos de tipo de veh√≠culo
df_vehiculo_victima = df[
    (df['victima_vehiculo_ampliado'].notna()) &
    (df['victima_vehiculo_ampliado'] != 'No corresponde') &
    (df['victima_vehiculo_ampliado'] != 'Sin determinar') &
    (df['victima_vehiculo_ampliado'] != '-----')
]

# Conteo y gr√°fico
plt.figure(figsize=(10, 5))
sns.countplot(data=df_vehiculo_victima, x='victima_vehiculo_ampliado', order=df_vehiculo_victima['victima_vehiculo_ampliado'].value_counts().index)
plt.title('Tipo de Veh√≠culo de las V√≠ctimas')
plt.xlabel('Tipo de Veh√≠culo')
plt.ylabel('Cantidad de Accidentes')
plt.xticks(rotation=45)
plt.show()

# Filtrar registros v√°lidos (sin vac√≠os ni NaN)
df_vehiculo_victima_validos = df_vehiculo_victima[
    (df_vehiculo_victima['victima_vehiculo_ampliado'].notna()) &
    (df_vehiculo_victima['victima_vehiculo_ampliado'] != '')
]

# Agrupamiento por tipo de veh√≠culo de las v√≠ctimas
accidentes_vehiculo = df_vehiculo_victima_validos['victima_vehiculo_ampliado'].value_counts().reset_index()
accidentes_vehiculo.columns = ['tipo_vehiculo', 'cantidad']

# Exportar CSV limpio
accidentes_vehiculo.to_csv('vehiculo_de_las_victimas.csv', index=False)

# Descargar CSV
from google.colab import files
files.download('vehiculo_de_las_victimas.csv')

"""### An√°lisis de Sexo de las V√≠ctimas  
Se analiza la distribuci√≥n por sexo de las personas v√≠ctimas de accidentes de tr√°nsito.  
Solo se consideran registros con informaci√≥n v√°lida.  

"""

# Sanitizaci√≥n puntual de la columna victima_sexo
df['victima_sexo'] = df['victima_sexo'].replace(['Sin determinar', 'No corresponde'], np.nan)

# Filtrar datos v√°lidos de sexo
df_sexo_victima = df[df['victima_sexo'].notna()]

# Conteo y gr√°fico
plt.figure(figsize=(6, 4))
sns.countplot(data=df_sexo_victima, x='victima_sexo')
plt.title('Distribuci√≥n por Sexo de las V√≠ctimas')
plt.xlabel('Sexo')
plt.ylabel('Cantidad de Accidentes')
plt.show()

# Agrupamiento por sexo de las v√≠ctimas
sexo_victimas = df_victimas['victima_sexo'].value_counts().reset_index()
sexo_victimas.columns = ['sexo', 'cantidad']

# Exportar CSV
sexo_victimas.to_csv('sexo_victimas.csv', index=False)
files.download('sexo_victimas.csv')

"""### An√°lisis de Grupos Etarios de Inculpados  
Se analiza la distribuci√≥n de edad de las personas inculpadas en accidentes de tr√°nsito.  
Para este an√°lisis, se filtran los registros con un dato v√°lido en la variable de edad.  

"""

# Filtrar datos v√°lidos de edad de inculpados
df_inculpados = df[
    (df['inculpado_tr_edad'].notna()) &
    (df['inculpado_tr_edad'] != 'No corresponde') &
    (df['inculpado_tr_edad'] != 'Sin determinar')
]

# Conteo y gr√°fico
plt.figure(figsize=(10, 5))
sns.countplot(data=df_inculpados, x='inculpado_tr_edad', order=sorted(df_inculpados['inculpado_tr_edad'].unique()))
plt.title('Distribuci√≥n de Edad de los Inculpados')
plt.xlabel('Grupo Etario')
plt.ylabel('Cantidad de Accidentes')
plt.xticks(rotation=45)
plt.show()

"""### An√°lisis por Tipo de Veh√≠culo de los Inculpados  
Se analiza qu√© tipo de veh√≠culo conduc√≠an los inculpados al momento de los accidentes.  
Solo se consideran registros con informaci√≥n v√°lida.  

"""

# Filtrar datos v√°lidos de tipo de veh√≠culo
df_vehiculo_inculpado = df[
    (df['inculpado_vehiculo_ampliado'].notna()) &
    (df['inculpado_vehiculo_ampliado'] != 'No corresponde') &
    (df['inculpado_vehiculo_ampliado'] != 'Sin determinar') &
    (df['inculpado_vehiculo_ampliado'] != '-----')
]

# Conteo y gr√°fico
plt.figure(figsize=(10, 5))
sns.countplot(data=df_vehiculo_inculpado, x='inculpado_vehiculo_ampliado', order=df_vehiculo_inculpado['inculpado_vehiculo_ampliado'].value_counts().index)
plt.title('Tipo de Veh√≠culo de los Inculpados')
plt.xlabel('Tipo de Veh√≠culo')
plt.ylabel('Cantidad de Accidentes')
plt.xticks(rotation=45)
plt.show()

# Agrupamiento por tipo de veh√≠culo de los inculpados
vehiculo_inculpados = df_inculpados['inculpado_vehiculo_ampliado'].value_counts().reset_index()
vehiculo_inculpados.columns = ['tipo_vehiculo', 'cantidad']

# Exportar CSV
vehiculo_inculpados.to_csv('vehiculo_inculpados.csv', index=False)
from google.colab import files
files.download('vehiculo_inculpados.csv')

"""## T√©cnica de Miner√≠a de Datos: Clustering Geogr√°fico (KMeans)  
Para complementar el an√°lisis, se aplica la t√©cnica de agrupamiento (clustering) utilizando el algoritmo KMeans.  
El objetivo es detectar zonas geogr√°ficas con alta concentraci√≥n de accidentes, lo que permite identificar "puntos calientes" de siniestralidad.  

"""

from sklearn.cluster import KMeans

# Filtrar datos v√°lidos de latitud y longitud y convertirlos a num√©rico
df_cluster = df.copy()
df_cluster['latitud'] = pd.to_numeric(df_cluster['latitud'], errors='coerce')
df_cluster['longitud'] = pd.to_numeric(df_cluster['longitud'], errors='coerce')
df_cluster = df_cluster.dropna(subset=['latitud', 'longitud'])

# Selecci√≥n de variables para clustering
coords = df_cluster[['latitud', 'longitud']].to_numpy()

# Definir cantidad de clusters (se puede ajustar, en este caso elegimos 5)
kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)
kmeans.fit(coords)

# Agregar los clusters al dataframe
df_cluster['cluster'] = kmeans.labels_

"""### Visualizaci√≥n de Clusters Geogr√°ficos  
A continuaci√≥n, se visualizan los clusters identificados mediante KMeans en un mapa interactivo.  
Cada color representa un grupo de accidentes que comparten cercan√≠a geogr√°fica, es decir, pertenecen a una misma zona de alta concentraci√≥n de siniestros.  

Los colores no tienen un significado cualitativo espec√≠fico (ejemplo: gravedad o tipo de accidente), sino que simplemente distinguen visualmente los diferentes grupos identificados por el algoritmo.  

"""

# Colores para los clusters
colores = ['red', 'blue', 'green', 'orange', 'purple']

# Crear el mapa centrado en Argentina
m_clusters = folium.Map(location=[-38.41, -63.61], zoom_start=4)

# Agregar puntos al mapa seg√∫n el cluster
for _, row in df_cluster.iterrows():
    folium.CircleMarker(
        location=[row['latitud'], row['longitud']],
        radius=2,
        color=colores[row['cluster'] % len(colores)],
        fill=True,
        fill_opacity=0.5
    ).add_to(m_clusters)

# Leyenda detallada
legend_html = '''
<div style="position: fixed;
     bottom: 50px; left: 50px; width: 250px; height: 160px;
     background-color: white; z-index:9999; font-size:14px;
     border:2px solid grey; padding: 10px;">
<b>Clusters de Accidentes</b><br>
Rojo ‚Üí Cluster 0<br>
Azul ‚Üí Cluster 1<br>
Verde ‚Üí Cluster 2<br>
Naranja ‚Üí Cluster 3<br>
Violeta ‚Üí Cluster 4<br>
</div>
'''

m_clusters.get_root().html.add_child(folium.Element(legend_html))

m_clusters

# Crear DataFrame con latitud, longitud y cluster
df_clusters_export = df_cluster[['latitud', 'longitud', 'cluster']].copy()

# Exportar CSV
df_clusters_export.to_csv('datos_clusters_mapa.csv', index=False)

# Descargar el CSV listo para Looker
from google.colab import files
files.download('datos_clusters_mapa.csv')

"""## Analisis Predictivo Utilizando Prophet
El objetivo de este an√°lisis predictivo es estimar c√≥mo podr√≠a evolucionar la cantidad de accidentes de tr√°nsito en Argentina en los pr√≥ximos meses, bas√°ndose en los datos hist√≥ricos disponibles.

Este tipo de proyecci√≥n permite anticipar posibles escenarios futuros y detectar tendencias o patrones estacionales, lo que resulta √∫til para la toma de decisiones en materia de prevenci√≥n y seguridad vial.
"""

from prophet import Prophet
from google.colab import files
import pandas as pd

# ‚úÖ Aseguramos que la columna de fecha est√© en formato datetime
df['fecha_hecho'] = pd.to_datetime(df['fecha_hecho'])

# üìä Agrupamos los accidentes por mes y contamos la cantidad
accidentes_mensuales = df.groupby(df['fecha_hecho'].dt.to_period('M')).size().reset_index(name='cantidad_accidentes')
accidentes_mensuales['fecha_hecho'] = accidentes_mensuales['fecha_hecho'].dt.to_timestamp()

# üéØ Preparamos el DataFrame para Prophet
df_prophet = accidentes_mensuales.rename(columns={'fecha_hecho': 'ds', 'cantidad_accidentes': 'y'})

# ‚úÖ Mostramos los datos con nombres claros
display(df_prophet.rename(columns={'ds': 'fecha', 'y': 'cantidad_accidentes'}).head())

# üîÆ Creamos y entrenamos el modelo
modelo = Prophet()
modelo.fit(df_prophet)

# üóìÔ∏è Generamos fechas futuras para predecir (en este caso, 6 meses adicionales)
futuro = modelo.make_future_dataframe(periods=6, freq='MS')

# üìà Obtenemos la predicci√≥n para todo el rango de fechas (pasado y futuro)
pronostico = modelo.predict(futuro)

# ‚úÖ Renombramos las columnas para facilitar la interpretaci√≥n
pronostico_renombrado = pronostico.rename(columns={
    'ds': 'fecha',
    'yhat': 'prediccion',
    'yhat_lower': 'rango_inferior',
    'yhat_upper': 'rango_superior'
})

# ‚úÖ Obtenemos la √∫ltima fecha real de tu dataset
fecha_max = df['fecha_hecho'].max()

# üéØ Filtramos solo los meses posteriores al √∫ltimo dato real (predicci√≥n futura)
pronostico_futuro = pronostico_renombrado[pronostico_renombrado['fecha'] > fecha_max]

"""### Visualizaci√≥n de Predicciones
A continuaci√≥n, se presentan las predicciones generadas por el modelo Prophet.  
Este an√°lisis permite estimar c√≥mo podr√≠a evolucionar la cantidad de accidentes de tr√°nsito en los pr√≥ximos meses, bas√°ndose en los patrones temporales observados en los datos hist√≥ricos.  
La proyecci√≥n facilita la detecci√≥n anticipada de posibles aumentos o disminuciones en la siniestralidad, brindando informaci√≥n √∫til para la planificaci√≥n y la toma de decisiones en materia de prevenci√≥n.

"""

# üñºÔ∏è Gr√°fico principal de predicci√≥n
fig = modelo.plot(pronostico)
plt.title('Predicci√≥n mensual de accidentes de tr√°nsito en Argentina')
plt.show()

"""Comentarios explicativos del gr√°fico:
- Puntos negros: valores reales observados de accidentes en cada mes.
- L√≠nea azul: predicci√≥n del modelo para la cantidad de accidentes.
- √Årea celeste: rango de incertidumbre (intervalo de confianza); el modelo estima que, con alta probabilidad, los valores reales estar√°n dentro de esa zona.
"""

# üîç Gr√°fico de componentes de la predicci√≥n
fig2 = modelo.plot_components(pronostico)
plt.show()

"""**Comentarios explicativos de los componentes:**

*Primer gr√°fico - Tendencia (Trend):*
- Muestra la evoluci√≥n general en la cantidad de accidentes a lo largo del tiempo.  
- Si la curva sube, indica un aumento en los accidentes.  
- Si la curva baja, indica una disminuci√≥n en los accidentes.  

*Segundo gr√°fico - Estacionalidad anual (Yearly):*
- Representa los patrones que se repiten todos los a√±os.  
- Permite identificar en qu√© meses del a√±o, hist√≥ricamente, hay m√°s o menos accidentes.

Prophet genera predicciones tanto para el pasado como para el futuro. Esto permite comparar si el modelo se ajusta bien a los datos hist√≥ricos antes de confiar en las predicciones futuras. Aunque ya tengamos datos reales hasta diciembre 2023, el modelo los "desconoce" al momento de predecir y genera estimaciones para todo el rango de fechas.
"""