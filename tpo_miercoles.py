# -*- coding: utf-8 -*-
"""TPO MIERCOLES NUEVO

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ux-tL65CVQUHia6x2HjlWOLPebk7BtJL

### Objetivo del Proyecto  
Este trabajo tiene como propósito analizar los accidentes de tránsito ocurridos en Argentina entre 2017 y 2023.  
A partir de un enfoque exploratorio y de minería de datos, se busca identificar patrones temporales, geográficos y sociodemográficos asociados a la siniestralidad vial.  
La finalidad es aportar información útil para la toma de decisiones en materia de prevención y seguridad vial.

## Hipótesis Principal  
Existen zonas geográficas y franjas horarias donde los accidentes de tránsito se concentran significativamente, lo que permite identificar puntos críticos de siniestralidad.

## Hipótesis Secundaria  
Las personas jóvenes (menores de 25 años) y los motociclistas presentan una mayor participación en los accidentes de tránsito en comparación con otros grupos etarios y tipos de vehículo.

## Dominio del Negocio y Relevancia  
La siniestralidad vial representa un problema social y económico de alta relevancia en Argentina.  
El análisis de datos de accidentes permite generar conocimiento para las autoridades de seguridad vial, municipios y organismos públicos, contribuyendo al diseño de políticas de prevención más eficaces y focalizadas.

## Técnica de Minería de Datos Aplicada: Clustering Geográfico  
Para detectar zonas de alta concentración de accidentes se aplicó la técnica de agrupamiento (clustering) mediante el algoritmo KMeans.  
Este método permitió identificar grupos de siniestros en función de su ubicación geográfica, generando conocimiento valioso sobre los llamados "puntos calientes" de siniestralidad.

## Conclusiones Finales  
El análisis exploratorio y la aplicación de técnicas de minería de datos permitieron identificar los siguientes hallazgos relevantes:  

✔ Los fines de semana y los horarios nocturnos concentran una mayor cantidad de accidentes.  
✔ Los motociclistas y las personas jóvenes se destacan como grupos de mayor participación en los siniestros.  
✔ Se identificaron zonas geográficas críticas de alta concentración de accidentes mediante clustering geográfico.  

Estos resultados constituyen una base sólida para diseñar políticas de prevención focalizadas y orientar los recursos en materia de seguridad vial.

# Análisis de Accidentes de Tránsito en Argentina (2017-2023)
Trabajo Práctico - Ciencia de Datos - UADE  
Integrantes:

## Introducción  
En el presente trabajo se analizarán los accidentes de tránsito registrados en Argentina entre los años 2017 y 2023, utilizando un dataset público provisto por la Subsecretaría de Transporte.  
El objetivo es identificar patrones espaciales, temporales y sociodemográficos asociados a la siniestralidad vial, con el fin de aportar información útil para la toma de decisiones en materia de seguridad vial.  
Se busca determinar si existen zonas críticas, franjas horarias o grupos poblacionales con mayor incidencia de accidentes.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import folium
from IPython.display import display
import re

"""## Carga de Datos  
A continuación, se carga el dataset con los registros de accidentes de tránsito y se visualizan las primeras filas para conocer su estructura.  

"""

import pandas as pd
# Reemplazá el siguiente link por el link de descarga directa
url = 'https://raw.githubusercontent.com/AugustoMartinez10/tpo-analisis-sube/refs/heads/main/SAT-MV-BU_2017-2023.csv'

df = pd.read_csv(url, sep=None, engine='python')

display(df.head())

"""## Sanitización y Preparación de los Datos  
Se realiza un proceso de limpieza para garantizar la correcta manipulación de los datos.  
Se eliminan columnas irrelevantes para el análisis, se renombran algunas variables y se verifica la existencia de valores nulos.  
También se estandarizan las fechas y se crean variables nuevas que facilitarán los análisis posteriores.  

"""

# Visualizamos las columnas para identificar las relevantes
df.columns.tolist()

# Selección de columnas clave para el análisis
columnas_relevantes = [
    'provincia_nombre', 'departamento_nombre', 'localidad_nombre',
    'latitud', 'longitud',
    'fecha_hecho', 'hora_hecho',
    'victima_sexo', 'victima_tr_edad', 'victima_vehiculo_ampliado',
    'inculpado_sexo', 'inculpado_tr_edad', 'inculpado_vehiculo_ampliado'
]

df = df[columnas_relevantes]
display(df.head())

# Sanitización general de columnas de texto
# Reemplazo de guiones, "Sin determinar" y "No corresponde" por NaN
for col in df.select_dtypes(include='object').columns:
    df[col] = df[col].replace(to_replace=r'^-+$', value=np.nan, regex=True)
    df[col] = df[col].replace(['Sin determinar', 'No corresponde'], np.nan)

# Conversión de fecha y extracción de variables adicionales
df['fecha_hecho'] = pd.to_datetime(df['fecha_hecho'], errors='coerce')
df['año'] = df['fecha_hecho'].dt.year
df['mes'] = df['fecha_hecho'].dt.month
df['dia_semana'] = df['fecha_hecho'].dt.day_name()

# Conversión de hora a formato de 24 hs
# Filtrar valores válidos antes de convertir
df_hora = df[
    (df['hora_hecho'].notna()) &
    (df['hora_hecho'] != 'Sin determinar') &
    (df['hora_hecho'] != 'No corresponde') &
    (df['hora_hecho'] != 'Perdido')
].copy()

# Convertir solo los válidos
df_hora['hora'] = pd.to_datetime(df_hora['hora_hecho'], format='%H:%M:%S', errors='coerce').dt.hour
display(df_hora.head())

# Revisión de valores faltantes
df.isnull().sum()

"""## Análisis Exploratorio de los Datos  
A continuación, se realiza un análisis preliminar de la información para detectar patrones temporales y geográficos en la siniestralidad vial.  
Este paso permite comprender mejor la distribución de los accidentes en función de variables como el día de la semana, la hora y la ubicación.

### Distribución de Accidentes por Día de la Semana  
Se analiza la cantidad de accidentes ocurridos en cada día de la semana para identificar posibles picos de siniestralidad.
"""

# Se eliminan registros sin fecha válida
df_filtrado = df.dropna(subset=['dia_semana'])

# Conteo y gráfico
plt.figure(figsize=(8, 5))
orden_dias = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
sns.countplot(data=df_filtrado, x='dia_semana', order=orden_dias)
plt.title('Cantidad de Accidentes por Día de la Semana')
plt.xlabel('Día')
plt.ylabel('Cantidad de Accidentes')
plt.xticks(rotation=45)
plt.show()

# Agrupamiento de accidentes por día de la semana
accidentes_dia = df_filtrado['dia_semana'].value_counts().reset_index()
accidentes_dia.columns = ['dia_semana', 'cantidad']

# Exportar CSV
accidentes_dia.to_csv('accidentes_por_dia.csv', index=False)

# Descargar CSV
from google.colab import files
files.download('accidentes_por_dia.csv')

"""### Distribución de Accidentes por Hora del Día  
Se analiza la cantidad de accidentes en función del horario para detectar franjas horarias de mayor siniestralidad.  

"""

# Se eliminan registros sin hora válida
df_filtrado_hora = df_hora.dropna(subset=['hora'])

plt.figure(figsize=(8, 5))
sns.histplot(df_filtrado_hora['hora'], bins=24, kde=False)
plt.title('Distribución Horaria de los Accidentes')
plt.xlabel('Hora del Día')
plt.ylabel('Cantidad de Accidentes')
plt.show()

# Agrupamiento de accidentes por hora
accidentes_hora = df_filtrado_hora['hora'].value_counts().sort_index().reset_index()
accidentes_hora.columns = ['hora', 'cantidad']

# Exportar CSV
accidentes_hora.to_csv('accidentes_por_hora.csv', index=False)

# Descargar CSV
files.download('accidentes_por_hora.csv')

"""### Visualización Geográfica de Accidentes  
Se genera un mapa interactivo que permite observar la ubicación de los accidentes registrados.  
Debido al tamaño del dataset, se filtran solo los registros que tienen coordenadas válidas.  


"""

# Copia del dataframe para evitar modificar el original
df_mapa = df.copy()

# Convertir latitud y longitud a numérico, ignorando errores
df_mapa['latitud'] = pd.to_numeric(df_mapa['latitud'], errors='coerce')
df_mapa['longitud'] = pd.to_numeric(df_mapa['longitud'], errors='coerce')

# Filtrar solo los registros válidos
df_mapa = df_mapa.dropna(subset=['latitud', 'longitud'])

# Crear mapa centrado en Argentina
m = folium.Map(location=[-38.41, -63.61], zoom_start=4)

# Agregar puntos al mapa
for _, row in df_mapa.iterrows():
    folium.CircleMarker(
        location=[row['latitud'], row['longitud']],
        radius=2,
        color='red',
        fill=True,
        fill_opacity=0.5
    ).add_to(m)

m

"""### Análisis de Grupos Etarios de Víctimas  
Se analiza la distribución de edad de las víctimas de accidentes de tránsito.  
Para este análisis, se filtran los registros que contienen un dato válido en la variable de edad.  

"""

# Filtrar datos válidos de edad de víctimas
df_victimas = df[
    (df['victima_tr_edad'].notna()) &
    (df['victima_tr_edad'] != 'No corresponde') &
    (df['victima_tr_edad'] != 'Sin determinar')
]

# Conteo por grupo etario
plt.figure(figsize=(10, 5))
sns.countplot(data=df_victimas, x='victima_tr_edad', order=sorted(df_victimas['victima_tr_edad'].unique()))
plt.title('Distribución de Edad de las Víctimas')
plt.xlabel('Grupo Etario')
plt.ylabel('Cantidad de Accidentes')
plt.xticks(rotation=45)
plt.show()

# Agrupamiento por edad de las víctimas
edad_victimas = df_victimas['victima_tr_edad'].value_counts().reset_index()
edad_victimas.columns = ['edad', 'cantidad']

# Exportar CSV
edad_victimas.to_csv('edad_victimas.csv', index=False)
from google.colab import files
files.download('edad_victimas.csv')

"""### Análisis por Tipo de Vehículo de las Víctimas  
Se analiza qué tipo de vehículo conducían o en qué se transportaban las víctimas involucradas en los accidentes.  
Se filtran los registros que tienen un dato válido en esta variable.  

"""

# Filtrar datos válidos de tipo de vehículo
df_vehiculo_victima = df[
    (df['victima_vehiculo_ampliado'].notna()) &
    (df['victima_vehiculo_ampliado'] != 'No corresponde') &
    (df['victima_vehiculo_ampliado'] != 'Sin determinar') &
    (df['victima_vehiculo_ampliado'] != '-----')
]

# Conteo y gráfico
plt.figure(figsize=(10, 5))
sns.countplot(data=df_vehiculo_victima, x='victima_vehiculo_ampliado', order=df_vehiculo_victima['victima_vehiculo_ampliado'].value_counts().index)
plt.title('Tipo de Vehículo de las Víctimas')
plt.xlabel('Tipo de Vehículo')
plt.ylabel('Cantidad de Accidentes')
plt.xticks(rotation=45)
plt.show()

# Filtrar registros válidos (sin vacíos ni NaN)
df_vehiculo_victima_validos = df_vehiculo_victima[
    (df_vehiculo_victima['victima_vehiculo_ampliado'].notna()) &
    (df_vehiculo_victima['victima_vehiculo_ampliado'] != '')
]

# Agrupamiento por tipo de vehículo de las víctimas
accidentes_vehiculo = df_vehiculo_victima_validos['victima_vehiculo_ampliado'].value_counts().reset_index()
accidentes_vehiculo.columns = ['tipo_vehiculo', 'cantidad']

# Exportar CSV limpio
accidentes_vehiculo.to_csv('vehiculo_de_las_victimas.csv', index=False)

# Descargar CSV
from google.colab import files
files.download('vehiculo_de_las_victimas.csv')

"""### Análisis de Sexo de las Víctimas  
Se analiza la distribución por sexo de las personas víctimas de accidentes de tránsito.  
Solo se consideran registros con información válida.  

"""

# Sanitización puntual de la columna victima_sexo
df['victima_sexo'] = df['victima_sexo'].replace(['Sin determinar', 'No corresponde'], np.nan)

# Filtrar datos válidos de sexo
df_sexo_victima = df[df['victima_sexo'].notna()]

# Conteo y gráfico
plt.figure(figsize=(6, 4))
sns.countplot(data=df_sexo_victima, x='victima_sexo')
plt.title('Distribución por Sexo de las Víctimas')
plt.xlabel('Sexo')
plt.ylabel('Cantidad de Accidentes')
plt.show()

# Agrupamiento por sexo de las víctimas
sexo_victimas = df_victimas['victima_sexo'].value_counts().reset_index()
sexo_victimas.columns = ['sexo', 'cantidad']

# Exportar CSV
sexo_victimas.to_csv('sexo_victimas.csv', index=False)
files.download('sexo_victimas.csv')

"""### Análisis de Grupos Etarios de Inculpados  
Se analiza la distribución de edad de las personas inculpadas en accidentes de tránsito.  
Para este análisis, se filtran los registros con un dato válido en la variable de edad.  

"""

# Filtrar datos válidos de edad de inculpados
df_inculpados = df[
    (df['inculpado_tr_edad'].notna()) &
    (df['inculpado_tr_edad'] != 'No corresponde') &
    (df['inculpado_tr_edad'] != 'Sin determinar')
]

# Conteo y gráfico
plt.figure(figsize=(10, 5))
sns.countplot(data=df_inculpados, x='inculpado_tr_edad', order=sorted(df_inculpados['inculpado_tr_edad'].unique()))
plt.title('Distribución de Edad de los Inculpados')
plt.xlabel('Grupo Etario')
plt.ylabel('Cantidad de Accidentes')
plt.xticks(rotation=45)
plt.show()

"""### Análisis por Tipo de Vehículo de los Inculpados  
Se analiza qué tipo de vehículo conducían los inculpados al momento de los accidentes.  
Solo se consideran registros con información válida.  

"""

# Filtrar datos válidos de tipo de vehículo
df_vehiculo_inculpado = df[
    (df['inculpado_vehiculo_ampliado'].notna()) &
    (df['inculpado_vehiculo_ampliado'] != 'No corresponde') &
    (df['inculpado_vehiculo_ampliado'] != 'Sin determinar') &
    (df['inculpado_vehiculo_ampliado'] != '-----')
]

# Conteo y gráfico
plt.figure(figsize=(10, 5))
sns.countplot(data=df_vehiculo_inculpado, x='inculpado_vehiculo_ampliado', order=df_vehiculo_inculpado['inculpado_vehiculo_ampliado'].value_counts().index)
plt.title('Tipo de Vehículo de los Inculpados')
plt.xlabel('Tipo de Vehículo')
plt.ylabel('Cantidad de Accidentes')
plt.xticks(rotation=45)
plt.show()

# Agrupamiento por tipo de vehículo de los inculpados
vehiculo_inculpados = df_inculpados['inculpado_vehiculo_ampliado'].value_counts().reset_index()
vehiculo_inculpados.columns = ['tipo_vehiculo', 'cantidad']

# Exportar CSV
vehiculo_inculpados.to_csv('vehiculo_inculpados.csv', index=False)
from google.colab import files
files.download('vehiculo_inculpados.csv')

"""## Técnica de Minería de Datos: Clustering Geográfico (KMeans)  
Para complementar el análisis, se aplica la técnica de agrupamiento (clustering) utilizando el algoritmo KMeans.  
El objetivo es detectar zonas geográficas con alta concentración de accidentes, lo que permite identificar "puntos calientes" de siniestralidad.  

"""

from sklearn.cluster import KMeans

# Filtrar datos válidos de latitud y longitud y convertirlos a numérico
df_cluster = df.copy()
df_cluster['latitud'] = pd.to_numeric(df_cluster['latitud'], errors='coerce')
df_cluster['longitud'] = pd.to_numeric(df_cluster['longitud'], errors='coerce')
df_cluster = df_cluster.dropna(subset=['latitud', 'longitud'])

# Selección de variables para clustering
coords = df_cluster[['latitud', 'longitud']].to_numpy()

# Definir cantidad de clusters (se puede ajustar, en este caso elegimos 5)
kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)
kmeans.fit(coords)

# Agregar los clusters al dataframe
df_cluster['cluster'] = kmeans.labels_

"""### Visualización de Clusters Geográficos  
A continuación, se visualizan los clusters identificados mediante KMeans en un mapa interactivo.  
Cada color representa un grupo de accidentes que comparten cercanía geográfica, es decir, pertenecen a una misma zona de alta concentración de siniestros.  

Los colores no tienen un significado cualitativo específico (ejemplo: gravedad o tipo de accidente), sino que simplemente distinguen visualmente los diferentes grupos identificados por el algoritmo.  

"""

# Colores para los clusters
colores = ['red', 'blue', 'green', 'orange', 'purple']

# Crear el mapa centrado en Argentina
m_clusters = folium.Map(location=[-38.41, -63.61], zoom_start=4)

# Agregar puntos al mapa según el cluster
for _, row in df_cluster.iterrows():
    folium.CircleMarker(
        location=[row['latitud'], row['longitud']],
        radius=2,
        color=colores[row['cluster'] % len(colores)],
        fill=True,
        fill_opacity=0.5
    ).add_to(m_clusters)

# Leyenda detallada
legend_html = '''
<div style="position: fixed;
     bottom: 50px; left: 50px; width: 250px; height: 160px;
     background-color: white; z-index:9999; font-size:14px;
     border:2px solid grey; padding: 10px;">
<b>Clusters de Accidentes</b><br>
Rojo → Cluster 0<br>
Azul → Cluster 1<br>
Verde → Cluster 2<br>
Naranja → Cluster 3<br>
Violeta → Cluster 4<br>
</div>
'''

m_clusters.get_root().html.add_child(folium.Element(legend_html))

m_clusters

# Crear DataFrame con latitud, longitud y cluster
df_clusters_export = df_cluster[['latitud', 'longitud', 'cluster']].copy()

# Exportar CSV
df_clusters_export.to_csv('datos_clusters_mapa.csv', index=False)

# Descargar el CSV listo para Looker
from google.colab import files
files.download('datos_clusters_mapa.csv')

"""## Analisis Predictivo Utilizando Prophet
El objetivo de este análisis predictivo es estimar cómo podría evolucionar la cantidad de accidentes de tránsito en Argentina en los próximos meses, basándose en los datos históricos disponibles.

Este tipo de proyección permite anticipar posibles escenarios futuros y detectar tendencias o patrones estacionales, lo que resulta útil para la toma de decisiones en materia de prevención y seguridad vial.
"""

from prophet import Prophet
from google.colab import files
import pandas as pd

# ✅ Aseguramos que la columna de fecha esté en formato datetime
df['fecha_hecho'] = pd.to_datetime(df['fecha_hecho'])

# 📊 Agrupamos los accidentes por mes y contamos la cantidad
accidentes_mensuales = df.groupby(df['fecha_hecho'].dt.to_period('M')).size().reset_index(name='cantidad_accidentes')
accidentes_mensuales['fecha_hecho'] = accidentes_mensuales['fecha_hecho'].dt.to_timestamp()

# 🎯 Preparamos el DataFrame para Prophet
df_prophet = accidentes_mensuales.rename(columns={'fecha_hecho': 'ds', 'cantidad_accidentes': 'y'})

# ✅ Mostramos los datos con nombres claros
display(df_prophet.rename(columns={'ds': 'fecha', 'y': 'cantidad_accidentes'}).head())

# 🔮 Creamos y entrenamos el modelo
modelo = Prophet()
modelo.fit(df_prophet)

# 🗓️ Generamos fechas futuras para predecir (en este caso, 6 meses adicionales)
futuro = modelo.make_future_dataframe(periods=6, freq='MS')

# 📈 Obtenemos la predicción para todo el rango de fechas (pasado y futuro)
pronostico = modelo.predict(futuro)

# ✅ Renombramos las columnas para facilitar la interpretación
pronostico_renombrado = pronostico.rename(columns={
    'ds': 'fecha',
    'yhat': 'prediccion',
    'yhat_lower': 'rango_inferior',
    'yhat_upper': 'rango_superior'
})

# ✅ Obtenemos la última fecha real de tu dataset
fecha_max = df['fecha_hecho'].max()

# 🎯 Filtramos solo los meses posteriores al último dato real (predicción futura)
pronostico_futuro = pronostico_renombrado[pronostico_renombrado['fecha'] > fecha_max]

"""### Visualización de Predicciones
A continuación, se presentan las predicciones generadas por el modelo Prophet.  
Este análisis permite estimar cómo podría evolucionar la cantidad de accidentes de tránsito en los próximos meses, basándose en los patrones temporales observados en los datos históricos.  
La proyección facilita la detección anticipada de posibles aumentos o disminuciones en la siniestralidad, brindando información útil para la planificación y la toma de decisiones en materia de prevención.

"""

# 🖼️ Gráfico principal de predicción
fig = modelo.plot(pronostico)
plt.title('Predicción mensual de accidentes de tránsito en Argentina')
plt.show()

"""Comentarios explicativos del gráfico:
- Puntos negros: valores reales observados de accidentes en cada mes.
- Línea azul: predicción del modelo para la cantidad de accidentes.
- Área celeste: rango de incertidumbre (intervalo de confianza); el modelo estima que, con alta probabilidad, los valores reales estarán dentro de esa zona.
"""

# 🔍 Gráfico de componentes de la predicción
fig2 = modelo.plot_components(pronostico)
plt.show()

"""**Comentarios explicativos de los componentes:**

*Primer gráfico - Tendencia (Trend):*
- Muestra la evolución general en la cantidad de accidentes a lo largo del tiempo.  
- Si la curva sube, indica un aumento en los accidentes.  
- Si la curva baja, indica una disminución en los accidentes.  

*Segundo gráfico - Estacionalidad anual (Yearly):*
- Representa los patrones que se repiten todos los años.  
- Permite identificar en qué meses del año, históricamente, hay más o menos accidentes.

Prophet genera predicciones tanto para el pasado como para el futuro. Esto permite comparar si el modelo se ajusta bien a los datos históricos antes de confiar en las predicciones futuras. Aunque ya tengamos datos reales hasta diciembre 2023, el modelo los "desconoce" al momento de predecir y genera estimaciones para todo el rango de fechas.
"""